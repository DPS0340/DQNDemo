<h1 align="center">Welcome to DQNDemo üëã</h1>
<p>
  <a href="#" target="_blank">
    <img alt="GitHub" src="https://img.shields.io/github/license/DPS0340/DQNDemo">
  </a>
</p>

> Deep Q-Learning from Demonstrations implementation using Pytorch & OpenAI Gym

[Paper link](2018-Deep_Q-Learning_from_Demonstrations-AAAI-406.pdf)

## Install

```sh
pip install -r requirements.txt
```

## Usage

```sh
python agent_1.py
```

## ü§ù Contributing

Contributions, issues and feature requests are welcome.<br />
Feel free to check [issues page](https://github.com/DPS0340/DQNDemo/issues) if you want to contribute.<br />

## Demo
![DQNDemo](https://user-images.githubusercontent.com/32592965/109403989-09729100-79a5-11eb-95eb-f2327e3078b9.gif)

## Output Graph
![simple DQN](https://github.com/DPS0340/DQNDemo/blob/master/plot_use_per_False.png)
![original DQN](https://github.com/DPS0340/DQNDemo/blob/master/plot_use_per_True.png)

### Simple vs Original

Simple DQN does not have PER algorithm, it selects from uniform distribution.\
Original is vice versa.

## Author

üë§ **jiho lee**

* Website: https://velog.io/@dps0340
* Github: [@DPS0340](https://github.com/DPS0340)

## Show your support

Give a ‚≠êÔ∏è if this project helped you!

***
_This README was generated with ‚ù§Ô∏è by [readme-md-generator](https://github.com/kefranabg/readme-md-generator)_
